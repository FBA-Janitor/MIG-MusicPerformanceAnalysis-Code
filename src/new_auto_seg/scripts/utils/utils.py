"""
Feb 04, 2024 @suncerock

This file contains util functions
These functions are all internal and should NEVER be called by users
"""

import csv
import os
from tqdm import tqdm

import librosa
import numpy as np

from .feature import write_feature
from .default_configs_path import norm_param_path


def _load_and_normalize_audio(audio_path, sr):
    x, _ = librosa.load(audio_path, sr=sr, mono=True)
    x = x / np.abs(x).max()
    return x

def _read_multiple_csv(csv_list):
    """
    Read multiple csv files (with no head) into one list
    Used in combining several csv generated by generate_audio_seg_path.py

    Parameter
    ----------
    csv_list: List[str]
        the list of csv files
    
    Return
    ----------
    List[List]
        (num_data, 3), List of [student_id, audio_file_path, segment_file_path]
    """
    mult_csv = []
    for csv_file in csv_list:
        with open(csv_file, 'r') as f:
            one_csv = csv.reader(f)
            for row in one_csv:
                mult_csv.append(row)
    return mult_csv

def _read_annotation_as_seg(seg_csv):
    """
    Read in the annotation csv file as segments

    Parameter
    ----------
    seg_csv: str
        path to the segmentation file
    
    Return
    ----------
    List[Tuple]
        (num_segments, 2), List of (start_time, end_time)
    """
    seg = []
    with open(seg_csv, 'r') as f:
        seg_reader = csv.DictReader(f)
        for row in seg_reader:
            seg.append((float(row["Start"]), float(row["End"])))
    return seg


def _read_annotation_as_label(time_stamp, seg_csv):
    """
    Read in the annotation file as label (0-1 vector)

    Parameters
    ----------
    time_stamp : np.ndarray
        the time stamp array corresponding to the segmentation file and the feature
    seg_csv : str
        path to the segmentation file

    Returns
    ----------
    np.ndarray
        a binary array containing the labels for training
    """
    seg = _read_annotation_as_seg(seg_csv)
    y = np.zeros_like(time_stamp)
    for start, end in seg:
        y[(time_stamp > start) & (time_stamp < end)] = 1
    return y

def _load_data(
    csv_list,
    feature_dir,

    sr=22050,
    block_size=4096,
    hop_size=2048
):
    """
    Load the feature and segmentation data

    Parameters
    ----------
    csv_list : List[str]
        list of path to the summary csv files for training
    feature_dir : str
        path to save the feature data, first check whether there is feature in it,
        write feature into this directory if no extracted features found
    sr : int, optional
        sampling rate, only used if no extracted features found, by default 22050
    block_size : int, optional
        block size for computing stft, only used if no extracted features found, by default 4096
    hop_size : int, optional
        hop size for computing stft, only used if no extracted features found, by default 2048

    Returns
    ----------
    np.ndarray
        (num_frame, num_feature), feature data
    np.ndarray
        (num_frame, ), label data
    """
    data_csv = _read_multiple_csv(csv_list)
    data_X, data_y = [], []
    for stu_id, audio_path, segment_path in tqdm(data_csv):

        # Load feature data
        feature_path = os.path.join(feature_dir, "{}.npz".format(stu_id))
        if os.path.exists(feature_path):
            with open(feature_path, 'rb') as f:
                feature_save = np.load(f)
                feature = feature_save['feature']
                time_stamp = feature_save['time_stamp']
        else:
            # continue
            audio = _load_and_normalize_audio(audio_path, sr=sr)

            # write feature into feature_write_dir
            feature, time_stamp = write_feature(audio, stu_id, feature_dir, sr, block_size, hop_size)
        
        # Load segmentation annotation
        anno = _read_annotation_as_label(time_stamp, segment_path)
        data_X.append(feature)
        data_y.append(anno)

    data_X = np.concatenate(data_X, axis=0)
    data_y = np.concatenate(data_y, axis=0)

    return data_X, data_y

def _normalize_data(X, norm_param_path=norm_param_path, force_regenerate=False):
    """
    Normalize the data as
        $$X_{norm} = \dfrac{X - X_{min}}{X_{max} - X_{min}}$$
    where the min-max value are calculated feature-wise and then saved

    Parameters
    ----------
    X: np.ndarray
        (num_frame, num_feature), unnormalized data
    norm_param_path: str
        .npz path to the normalization parameter, the min-max value
        if not found, compute the min-max value then save it into norm_param_path
    
    Return
    ----------
    np.ndarray
        same shape as input, normalized data
    """
    if not os.path.exists('{}.npz'.format(norm_param_path)) or force_regenerate:
        X_min = X.min(axis=0)
        X_max = X.max(axis=0)
        np.savez(norm_param_path, X_min=X_min, X_max=X_max)
        print("No normalization file found! Saving new to norm_params.npz")
    else:
        with open('{}.npz'.format(norm_param_path), 'rb') as f:
            norm = np.load(f)
            X_min = norm['X_min']
            X_max = norm['X_max']
    return (X - X_min) / (X_max - X_min)
